{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c927eac",
   "metadata": {},
   "source": [
    "# æ•™åŠ¡ç³»ç»Ÿ RAG + Text2SQL æ€§èƒ½ä¼˜åŒ–æŒ‡å—\n",
    "\n",
    "ä½œä¸ºä¸€åé«˜çº§å…¨æ ˆAIå¼€å‘ä¸“å®¶ï¼Œæœ¬ Notebook å°†æŒ‡å¯¼ä½ å®Œæˆå¯¹ä¸€ä¸ªåŸºäº **MySQL** å’Œ **å¤šæ–‡ä»¶ RAG** çš„æ•™åŠ¡ç³»ç»Ÿçš„æ€§èƒ½åˆ†æä¸ä¼˜åŒ–ã€‚æˆ‘ä»¬å°†ä»æ•°æ®åº“æŸ¥è¯¢ã€ç´¢å¼•ç­–ç•¥ï¼Œåˆ° RAG ç®¡é“ä¸­çš„æ•°æ®åŠ è½½ã€åˆ†å—ã€åµŒå…¥ã€æ£€ç´¢ç­‰ç¯èŠ‚ï¼Œè¿›è¡Œå…¨é¢çš„è¯Šæ–­å’Œæ”¹è¿›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f160a1",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®ä¸æ•°æ®åº“è¿æ¥\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `pymysql` è¿æ¥æ•°æ®åº“ï¼Œ`SQLAlchemy` ä½œä¸º ORMï¼Œ`pandas` è¿›è¡Œæ•°æ®å¤„ç†ï¼Œä»¥åŠ `langchain` ä½œä¸º RAG æ¡†æ¶ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- å¯¼å…¥æ‰€éœ€åº“ã€‚\n",
    "- ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ä¸­å®‰å…¨åœ°åŠ è½½æ•°æ®åº“å‡­æ®ã€‚\n",
    "- åˆ›å»ºä¸€ä¸ª SQLAlchemy å¼•æ“ï¼Œå¹¶æµ‹è¯•ä¸æ•™åŠ¡ç³»ç»Ÿ MySQL æ•°æ®åº“çš„è¿æ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4843eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼\n",
      " |--- æµ‹è¯•æŸ¥è¯¢ (SELECT 1) è¿”å›: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ .env æ–‡ä»¶ï¼Œå¦‚æœæ‚¨çš„å‡­æ®å­˜å‚¨åœ¨å…¶ä¸­\n",
    "load_dotenv()\n",
    "\n",
    "# --- ä»ç¯å¢ƒå˜é‡æˆ–ç›´æ¥åœ¨æ­¤å¤„é…ç½®æ•°æ®åº“è¿æ¥ ---\n",
    "# å‚è€ƒæ‚¨çš„ 'æˆ‘çš„æ±‡æ€»å¤‡ä»½.ipynb'ï¼Œæˆ‘ä»¬ä½¿ç”¨ pymysql è¿æ¥\n",
    "# è¯·ç¡®ä¿æ‚¨çš„ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­åŒ…å«ä»¥ä¸‹ä¿¡æ¯\n",
    "DB_USER = os.getenv(\"DB_USER\", \"root\")  # æ‚¨çš„ MySQL ç”¨æˆ·å\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"Root123!\") # æ‚¨çš„ MySQL å¯†ç ï¼ˆå·²æ›´æ–°ä¸ºæ‚¨çš„å®é™…å¯†ç ï¼‰\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\") # æ•°æ®åº“ä¸»æœºï¼Œé€šå¸¸æ˜¯ localhost\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"3306\") # æ•°æ®åº“ç«¯å£ï¼Œé»˜è®¤ 3306\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"college_db\") # ç›®æ ‡æ•°æ®åº“åç§°\n",
    "\n",
    "# åˆ›å»º SQLAlchemy è¿æ¥å­—ç¬¦ä¸²\n",
    "# æˆ‘ä»¬ä½¿ç”¨ 'mysql+pymysql' ä½œä¸ºè¿æ¥å™¨\n",
    "DATABASE_URL = f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "try:\n",
    "    # åˆ›å»º SQLAlchemy å¼•æ“\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "\n",
    "    # æµ‹è¯•è¿æ¥\n",
    "    with engine.connect() as connection:\n",
    "        print(\"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼\")\n",
    "        # ç®€å•æŸ¥è¯¢ï¼ŒéªŒè¯è¿æ¥æœ‰æ•ˆ\n",
    "        result = connection.execute(text(\"SELECT 1\"))\n",
    "        print(\" |--- æµ‹è¯•æŸ¥è¯¢ (SELECT 1) è¿”å›:\", result.scalar())\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä½ çš„é…ç½®: {e}\")\n",
    "    print(\"   è¯·ç¡®ä¿ 'pymysql' å’Œ 'SQLAlchemy' å·²å®‰è£…: pip install pymysql sqlalchemy\")\n",
    "    engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca110c3",
   "metadata": {},
   "source": [
    "## 2. MySQL æ€§èƒ½åˆ†æä¸è¯Šæ–­\n",
    "\n",
    "æ€§èƒ½ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥æ˜¯è¯†åˆ«ç“¶é¢ˆã€‚å¯¹äº Text2SQL ç³»ç»Ÿï¼Œæœ€å¸¸è§çš„ç“¶é¢ˆæ˜¯æ•°æ®åº“ç«¯çš„æ…¢æŸ¥è¯¢ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `EXPLAIN` å‘½ä»¤æ¥åˆ†æé‚£äº›ç”± RAG ç³»ç»Ÿç”Ÿæˆçš„ã€æˆ–ä¸ RAG ç›¸å…³çš„ SQL æŸ¥è¯¢ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- è¯†åˆ«ä¸€ä¸ªæˆ–å¤šä¸ªåœ¨ RAG æµç¨‹ä¸­å¸¸ç”¨ä½†æ€§èƒ½å¯èƒ½ä¸ä½³çš„æŸ¥è¯¢ã€‚\n",
    "- ä½¿ç”¨ `EXPLAIN` åˆ†æè¿™äº›æŸ¥è¯¢çš„æ‰§è¡Œè®¡åˆ’ã€‚\n",
    "- é‡ç‚¹å…³æ³¨ `type`ï¼ˆæ˜¯å¦ä¸º `ALL`ï¼Œå³å…¨è¡¨æ‰«æï¼‰ã€`key`ï¼ˆæ˜¯å¦ä½¿ç”¨äº†ç´¢å¼•ï¼‰å’Œ `Extra`ï¼ˆæ˜¯å¦æœ‰ `Using filesort` æˆ– `Using temporary`ï¼‰ç­‰å­—æ®µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d008df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” å¯¹ä»¥ä¸‹æŸ¥è¯¢çš„ EXPLAIN åˆ†æç»“æœ:\n",
      "   '\n",
      "SELECT c.title, c.credits, d.dept_name\n",
      "FROM course AS c\n",
      "JOIN department AS d ON c.dept_name = d.dept_name\n",
      "WHERE c.title LIKE '%Introduction%' AND d.building = 'Watson';\n",
      "'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>select_type</th>\n",
       "      <th>table</th>\n",
       "      <th>partitions</th>\n",
       "      <th>type</th>\n",
       "      <th>possible_keys</th>\n",
       "      <th>key</th>\n",
       "      <th>key_len</th>\n",
       "      <th>ref</th>\n",
       "      <th>rows</th>\n",
       "      <th>filtered</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>d</td>\n",
       "      <td>None</td>\n",
       "      <td>ref</td>\n",
       "      <td>PRIMARY,idx_department_building</td>\n",
       "      <td>idx_department_building</td>\n",
       "      <td>63</td>\n",
       "      <td>const</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Using index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>c</td>\n",
       "      <td>None</td>\n",
       "      <td>ref</td>\n",
       "      <td>dept_name</td>\n",
       "      <td>dept_name</td>\n",
       "      <td>83</td>\n",
       "      <td>college_db.d.dept_name</td>\n",
       "      <td>10</td>\n",
       "      <td>11.11</td>\n",
       "      <td>Using where</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id select_type table partitions type                    possible_keys  \\\n",
       "0   1      SIMPLE     d       None  ref  PRIMARY,idx_department_building   \n",
       "1   1      SIMPLE     c       None  ref                        dept_name   \n",
       "\n",
       "                       key key_len                     ref  rows  filtered  \\\n",
       "0  idx_department_building      63                   const     1    100.00   \n",
       "1                dept_name      83  college_db.d.dept_name    10     11.11   \n",
       "\n",
       "         Extra  \n",
       "0  Using index  \n",
       "1  Using where  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_query(sql_query: str):\n",
    "    \"\"\"ä½¿ç”¨ EXPLAIN åˆ†æç»™å®šçš„ SQL æŸ¥è¯¢\"\"\"\n",
    "    if not engine:\n",
    "        print(\"æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•åˆ†ææŸ¥è¯¢ã€‚\")\n",
    "        return\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        # åœ¨æŸ¥è¯¢å‰åŠ ä¸Š EXPLAIN\n",
    "        explain_query = f\"EXPLAIN {sql_query}\"\n",
    "        try:\n",
    "            result = connection.execute(text(explain_query))\n",
    "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "            print(f\"ğŸ” å¯¹ä»¥ä¸‹æŸ¥è¯¢çš„ EXPLAIN åˆ†æç»“æœ:\")\n",
    "            print(f\"   '{sql_query}'\")\n",
    "            display(df)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ åˆ†ææŸ¥è¯¢æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "# --- ç¤ºä¾‹ï¼šåˆ†æä¸€ä¸ªå¯èƒ½ä½æ•ˆçš„æŸ¥è¯¢ ---\n",
    "# å‡è®¾æˆ‘ä»¬è¦æ ¹æ®è¯¾ç¨‹æ ‡é¢˜çš„å…³é”®è¯å’Œç³»åæ¥æŸ¥æ‰¾è¯¾ç¨‹\n",
    "# è¿™ä¸ªæŸ¥è¯¢åœ¨ `course.title` å’Œ `department.dept_name` ä¸Šæ²¡æœ‰ç´¢å¼•æ—¶å¯èƒ½ä¼šå¾ˆæ…¢\n",
    "slow_query_example = \"\"\"\n",
    "SELECT c.title, c.credits, d.dept_name\n",
    "FROM course AS c\n",
    "JOIN department AS d ON c.dept_name = d.dept_name\n",
    "WHERE c.title LIKE '%Introduction%' AND d.building = 'Watson';\n",
    "\"\"\"\n",
    "\n",
    "analyze_query(slow_query_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d47b23",
   "metadata": {},
   "source": [
    "## 3. æŸ¥è¯¢ä¼˜åŒ–ä¸ç´¢å¼•ç­–ç•¥\n",
    "\n",
    "æ ¹æ® `EXPLAIN` çš„åˆ†æç»“æœï¼Œæˆ‘ä»¬å¯ä»¥é‡‡å–æªæ–½ä¼˜åŒ–æŸ¥è¯¢ã€‚æœ€ç›´æ¥æœ‰æ•ˆçš„æ–¹æ³•æ˜¯ä¸ºæŸ¥è¯¢ä¸­ `WHERE` å­å¥å’Œ `JOIN` æ“ä½œæ¶‰åŠçš„åˆ—åˆ›å»ºç´¢å¼•ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- è¯†åˆ« `EXPLAIN` ç»“æœä¸­æœªä½¿ç”¨ç´¢å¼•çš„ `WHERE` æˆ– `JOIN` åˆ—ã€‚\n",
    "- ç¼–å†™ `CREATE INDEX` è¯­å¥ä¸ºè¿™äº›åˆ—æ·»åŠ ç´¢å¼•ã€‚\n",
    "- é‡æ–°è¿è¡Œ `EXPLAIN`ï¼ŒéªŒè¯æ–°ç´¢å¼•æ˜¯å¦è¢«æŸ¥è¯¢ä¼˜åŒ–å™¨ä½¿ç”¨ï¼ˆ`key` å­—æ®µåº”æ˜¾ç¤ºç´¢å¼•åç§°ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ce7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­£åœ¨å°è¯•åˆ›å»ºç´¢å¼•: CREATE INDEX idx_course_title ON course(title);\n",
      "âš ï¸ åˆ›å»ºç´¢å¼•æ—¶å‡ºç°é—®é¢˜ (å¯èƒ½æ˜¯ç´¢å¼•å·²å­˜åœ¨): (pymysql.err.OperationalError) (1061, \"Duplicate key name 'idx_course_title'\")\n",
      "[SQL: CREATE INDEX idx_course_title ON course(title);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "--- é‡æ–°åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ ---\n",
      "ğŸ” å¯¹ä»¥ä¸‹æŸ¥è¯¢çš„ EXPLAIN åˆ†æç»“æœ:\n",
      "   '\n",
      "SELECT c.title, c.credits, d.dept_name\n",
      "FROM course AS c\n",
      "JOIN department AS d ON c.dept_name = d.dept_name\n",
      "WHERE c.title LIKE '%Introduction%' AND d.building = 'Watson';\n",
      "'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>select_type</th>\n",
       "      <th>table</th>\n",
       "      <th>partitions</th>\n",
       "      <th>type</th>\n",
       "      <th>possible_keys</th>\n",
       "      <th>key</th>\n",
       "      <th>key_len</th>\n",
       "      <th>ref</th>\n",
       "      <th>rows</th>\n",
       "      <th>filtered</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>d</td>\n",
       "      <td>None</td>\n",
       "      <td>ref</td>\n",
       "      <td>PRIMARY,idx_department_building</td>\n",
       "      <td>idx_department_building</td>\n",
       "      <td>63</td>\n",
       "      <td>const</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Using index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>c</td>\n",
       "      <td>None</td>\n",
       "      <td>ref</td>\n",
       "      <td>dept_name</td>\n",
       "      <td>dept_name</td>\n",
       "      <td>83</td>\n",
       "      <td>college_db.d.dept_name</td>\n",
       "      <td>10</td>\n",
       "      <td>11.11</td>\n",
       "      <td>Using where</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id select_type table partitions type                    possible_keys  \\\n",
       "0   1      SIMPLE     d       None  ref  PRIMARY,idx_department_building   \n",
       "1   1      SIMPLE     c       None  ref                        dept_name   \n",
       "\n",
       "                       key key_len                     ref  rows  filtered  \\\n",
       "0  idx_department_building      63                   const     1    100.00   \n",
       "1                dept_name      83  college_db.d.dept_name    10     11.11   \n",
       "\n",
       "         Extra  \n",
       "0  Using index  \n",
       "1  Using where  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­£åœ¨å°è¯•åˆ›å»ºç´¢å¼•: CREATE INDEX idx_department_building ON department(building);\n",
      "âš ï¸ åˆ›å»ºç´¢å¼•æ—¶å‡ºç°é—®é¢˜ (å¯èƒ½æ˜¯ç´¢å¼•å·²å­˜åœ¨): (pymysql.err.OperationalError) (1061, \"Duplicate key name 'idx_department_building'\")\n",
      "[SQL: CREATE INDEX idx_department_building ON department(building);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "--- é‡æ–°åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ ---\n",
      "ğŸ” å¯¹ä»¥ä¸‹æŸ¥è¯¢çš„ EXPLAIN åˆ†æç»“æœ:\n",
      "   '\n",
      "SELECT c.title, c.credits, d.dept_name\n",
      "FROM course AS c\n",
      "JOIN department AS d ON c.dept_name = d.dept_name\n",
      "WHERE c.title LIKE '%Introduction%' AND d.building = 'Watson';\n",
      "'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>select_type</th>\n",
       "      <th>table</th>\n",
       "      <th>partitions</th>\n",
       "      <th>type</th>\n",
       "      <th>possible_keys</th>\n",
       "      <th>key</th>\n",
       "      <th>key_len</th>\n",
       "      <th>ref</th>\n",
       "      <th>rows</th>\n",
       "      <th>filtered</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>d</td>\n",
       "      <td>None</td>\n",
       "      <td>ref</td>\n",
       "      <td>PRIMARY,idx_department_building</td>\n",
       "      <td>idx_department_building</td>\n",
       "      <td>63</td>\n",
       "      <td>const</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Using index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>c</td>\n",
       "      <td>None</td>\n",
       "      <td>ref</td>\n",
       "      <td>dept_name</td>\n",
       "      <td>dept_name</td>\n",
       "      <td>83</td>\n",
       "      <td>college_db.d.dept_name</td>\n",
       "      <td>10</td>\n",
       "      <td>11.11</td>\n",
       "      <td>Using where</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id select_type table partitions type                    possible_keys  \\\n",
       "0   1      SIMPLE     d       None  ref  PRIMARY,idx_department_building   \n",
       "1   1      SIMPLE     c       None  ref                        dept_name   \n",
       "\n",
       "                       key key_len                     ref  rows  filtered  \\\n",
       "0  idx_department_building      63                   const     1    100.00   \n",
       "1                dept_name      83  college_db.d.dept_name    10     11.11   \n",
       "\n",
       "         Extra  \n",
       "0  Using index  \n",
       "1  Using where  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_and_verify_index(index_creation_sql: str, query_to_re_analyze: str):\n",
    "    \"\"\"åº”ç”¨ç´¢å¼•å¹¶é‡æ–°åˆ†ææŸ¥è¯¢ä»¥éªŒè¯æ•ˆæœ\"\"\"\n",
    "    if not engine:\n",
    "        print(\"æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•æ‰§è¡Œæ“ä½œã€‚\")\n",
    "        return\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            # å¼€å§‹ä¸€ä¸ªäº‹åŠ¡\n",
    "            trans = connection.begin()\n",
    "            print(f\"ğŸš€ æ­£åœ¨å°è¯•åˆ›å»ºç´¢å¼•: {index_creation_sql}\")\n",
    "            connection.execute(text(index_creation_sql))\n",
    "            trans.commit()\n",
    "            print(\"âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸï¼ˆæˆ–å·²å­˜åœ¨ï¼‰ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ åˆ›å»ºç´¢å¼•æ—¶å‡ºç°é—®é¢˜ (å¯èƒ½æ˜¯ç´¢å¼•å·²å­˜åœ¨): {e}\")\n",
    "            if 'trans' in locals() and trans.is_active:\n",
    "                trans.rollback()\n",
    "\n",
    "    # å†æ¬¡åˆ†ææŸ¥è¯¢\n",
    "    print(\"\\n--- é‡æ–°åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ ---\")\n",
    "    analyze_query(query_to_re_analyze)\n",
    "\n",
    "# --- ç¤ºä¾‹ï¼šä¸º `course.title` å’Œ `department.building` åˆ›å»ºç´¢å¼• ---\n",
    "# æ³¨æ„ï¼šå¯¹äº LIKE '%...%' æŸ¥è¯¢ï¼ŒB-Tree ç´¢å¼•æ•ˆæœæœ‰é™ï¼Œä½†å¯¹äºå‰ç¼€åŒ¹é…æˆ–å…¨æ–‡ç´¢å¼•åˆ™éå¸¸æœ‰æ•ˆã€‚\n",
    "# è¿™é‡Œæˆ‘ä»¬ä»ç„¶åˆ›å»ºä¸€ä¸ªå¸¸è§„ç´¢å¼•ä½œä¸ºç¤ºä¾‹ã€‚\n",
    "index_sql_1 = \"CREATE INDEX idx_course_title ON course(title);\"\n",
    "index_sql_2 = \"CREATE INDEX idx_department_building ON department(building);\"\n",
    "\n",
    "# ä¸º course.title åˆ›å»ºç´¢å¼•å¹¶éªŒè¯\n",
    "apply_and_verify_index(index_sql_1, slow_query_example)\n",
    "\n",
    "# ä¸º department.building åˆ›å»ºç´¢å¼•å¹¶éªŒè¯\n",
    "apply_and_verify_index(index_sql_2, slow_query_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82b6d2",
   "metadata": {},
   "source": [
    "## 4. RAG ç®¡é“åˆ†æï¼šæ•°æ®åŠ è½½ä¸åˆ†å—\n",
    "\n",
    "RAG çš„æ€§èƒ½ä¸ä»…å–å†³äºæ•°æ®åº“ï¼Œè¿˜ä¸¥é‡ä¾èµ–äºè¾“å…¥æ–‡æ¡£çš„è´¨é‡å’Œå¤„ç†æ–¹å¼ã€‚æˆ‘ä»¬å°†é¦–å…ˆåˆ†ææ•°æ®åŠ è½½å’Œæ–‡æœ¬åˆ†å—ï¼ˆChunkingï¼‰ç­–ç•¥ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- ä½¿ç”¨ `DirectoryLoader` (from `langchain`) æˆ–ç±»ä¼¼å·¥å…·åŠ è½½ä½ çš„å¤šæ–‡ä»¶çŸ¥è¯†åº“ï¼ˆä¾‹å¦‚ï¼Œæ•™å­¦å¤§çº²ã€å­¦ç”Ÿæ‰‹å†Œç­‰ï¼‰ã€‚\n",
    "- è¯„ä¼°å½“å‰çš„æ–‡æœ¬åˆ†å—ç­–ç•¥ã€‚ä¸€ä¸ªå¥½çš„åˆ†å—ç­–ç•¥åº”åœ¨ä¿æŒè¯­ä¹‰å®Œæ•´æ€§å’Œé™åˆ¶å•å—å¤§å°ä¹‹é—´å–å¾—å¹³è¡¡ã€‚\n",
    "- è¯•éªŒä¸åŒçš„ `chunk_size` å’Œ `chunk_overlap` å€¼ï¼Œè§‚å¯Ÿå®ƒä»¬å¦‚ä½•å½±å“æ£€ç´¢ä¸Šä¸‹æ–‡çš„è´¨é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3953e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸä» 'knowledge_base/docs' æ‰¹é‡åŠ è½½äº† 100 ä¸ªæ–‡æ¡£ã€‚\n",
      "\n",
      "--- ç­–ç•¥ 1 (chunk_size=128, overlap=20) ---\n",
      "ç”Ÿæˆäº† 1 ä¸ªå—ã€‚\n",
      "\n",
      "--- ç­–ç•¥ 2 (chunk_size=512, overlap=50) ---\n",
      "ç”Ÿæˆäº† 1 ä¸ªå—ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ç¡®ä¿å®‰è£…äº† langchain\n",
    "# !pip install langchain langchain-community langchain-text-splitters\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- 1. å‡†å¤‡å¹¶åŠ è½½æ–‡æ¡£ ---\n",
    "# ç›®æ ‡ç›®å½•\n",
    "DOCS_PATH = \"knowledge_base/docs\"\n",
    "NUM_FILES_TO_GENERATE = 100\n",
    "\n",
    "# è‡ªåŠ¨ç”Ÿæˆç¤ºä¾‹æ–‡ä»¶ï¼ˆå¦‚æœç›®å½•ä¸å­˜åœ¨æˆ–æ–‡ä»¶ä¸è¶³ï¼‰\n",
    "if not os.path.exists(DOCS_PATH) or len([f for f in os.listdir(DOCS_PATH) if f.endswith('.txt')]) < NUM_FILES_TO_GENERATE:\n",
    "    os.makedirs(DOCS_PATH, exist_ok=True)\n",
    "    print(f\"ç›®å½• '{DOCS_PATH}' ä¸å­˜åœ¨æˆ–æ–‡ä»¶ä¸è¶³ï¼Œæ­£åœ¨ç”Ÿæˆ {NUM_FILES_TO_GENERATE} ä¸ªç¤ºä¾‹æ–‡æ¡£...\")\n",
    "    for i in range(NUM_FILES_TO_GENERATE):\n",
    "        file_name = os.path.join(DOCS_PATH, f\"document_{i+1}.txt\")\n",
    "        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            if i == 0:\n",
    "                f.write(\"è¯¾ç¨‹: CS101, è®¡ç®—æœºç§‘å­¦å¯¼è®º. æˆè¯¾æ•™å¸ˆ: Alan Turing. æœ¬è¯¾ç¨‹æ¶µç›–ç®—æ³•ã€æ•°æ®ç»“æ„å’Œè®¡ç®—ç†è®ºçš„åŸºç¡€çŸ¥è¯†ã€‚\")\n",
    "            elif i == 1:\n",
    "                f.write(\"æ•™å­¦æ”¿ç­–: æ‰€æœ‰å­¦ç”Ÿå¿…é¡»éµå®ˆå­¦æœ¯è¯šä¿¡åŸåˆ™ï¼Œä¸¥ç¦æŠ„è¢­ã€‚å…³äºé€‰è¯¾å’Œé€€è¯¾çš„è¯¦ç»†è§„å®šè¯·å‚è€ƒå­¦ç”Ÿæ‰‹å†Œç¬¬5ç« ã€‚\")\n",
    "            else:\n",
    "                f.write(f\"è¿™æ˜¯ç¬¬ {i+1} å·æ•™å­¦æ–‡æ¡£çš„å ä½å†…å®¹ã€‚è¿™é‡Œå¯ä»¥åŒ…å«ä»»ä½•å…³äºè¯¾ç¨‹ã€æ”¿ç­–ã€æˆ–æ ¡å›­ç”Ÿæ´»çš„æ–‡æœ¬ä¿¡æ¯ã€‚\")\n",
    "    print(\"âœ… ç¤ºä¾‹æ–‡æ¡£ç”Ÿæˆå®Œæ¯•ã€‚\")\n",
    "\n",
    "# --- 2. æ‰¹é‡åŠ è½½æ–‡æ¡£ ---\n",
    "try:\n",
    "    loader = DirectoryLoader(DOCS_PATH, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
    "    documents = loader.load()\n",
    "    print(f\"âœ… æˆåŠŸä» '{DOCS_PATH}' æ‰¹é‡åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŠ è½½æ–‡æ¡£å¤±è´¥: {e}\")\n",
    "    documents = []\n",
    "\n",
    "# --- 3. è¯•éªŒä¸åŒçš„åˆ†å—ç­–ç•¥ ---\n",
    "if documents:\n",
    "    text_sample = documents[0].page_content\n",
    "\n",
    "    # ç­–ç•¥ 1: è¾ƒå°çš„å—ï¼Œè¾ƒå¤§çš„é‡å \n",
    "    splitter_small = RecursiveCharacterTextSplitter(chunk_size=128, chunk_overlap=20)\n",
    "    chunks_small = splitter_small.split_text(text_sample)\n",
    "    print(f\"\\n--- ç­–ç•¥ 1 (chunk_size=128, overlap=20) ---\")\n",
    "    print(f\"ç”Ÿæˆäº† {len(chunks_small)} ä¸ªå—ã€‚\")\n",
    "\n",
    "    # ç­–ç•¥ 2: è¾ƒå¤§çš„å—ï¼Œé€‚ä¸­çš„é‡å \n",
    "    splitter_large = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "    chunks_large = splitter_large.split_text(text_sample)\n",
    "    print(f\"\\n--- ç­–ç•¥ 2 (chunk_size=512, overlap=50) ---\")\n",
    "    print(f\"ç”Ÿæˆäº† {len(chunks_large)} ä¸ªå—ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cfba3",
   "metadata": {},
   "source": [
    "## 5. RAG ç®¡é“åˆ†æï¼šåµŒå…¥ä¸å‘é‡å­˜å‚¨ (LangChain + ChromaDB)\n",
    "\n",
    "åµŒå…¥æ¨¡å‹ï¼ˆEmbedding Modelï¼‰çš„è´¨é‡å’Œå‘é‡æ•°æ®åº“çš„æ•ˆç‡ç›´æ¥å½±å“æ£€ç´¢çš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- ä½¿ç”¨ LangChain å’Œ ChromaDB å°†æ–‡æ¡£åˆ‡ç‰‡å¹¶å‘é‡åŒ–å…¥åº“ã€‚\n",
    "- åŒæ—¶åœ¨ MySQL ä¸­åˆ›å»ºç´¢å¼•è¡¨ï¼Œè®°å½•æ–‡ä»¶åä¸å‘é‡ ID çš„å¯¹åº”å…³ç³»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62416d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä½¿ç”¨ DashScope åµŒå…¥æ¨¡å‹: 'text-embedding-v2'\n",
      "   åµŒå…¥å‘é‡ç»´åº¦: 1536\n",
      "âœ… æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼Œå…±ç”Ÿæˆ 100 ä¸ªæ–‡æœ¬å—ã€‚\n",
      "âœ… æ–‡æœ¬å—å·²å‘é‡åŒ–å¹¶å­˜å…¥ ChromaDBã€‚æ•°æ®åº“ä½ç½®: '/home/wangct/homework/text2sql/sqlmodel/chroma_db_langchain'\n",
      "âœ… æ–‡ä»¶-å‘é‡ç´¢å¼•è¡¨ 'file_vector_index' å·²æˆåŠŸåˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\n",
      "âœ… æˆåŠŸå°† 100 æ¡æ–‡ä»¶-å‘é‡æ˜ å°„å…³ç³»å†™å…¥ MySQL 'file_vector_index' è¡¨ã€‚\n",
      "âœ… æ£€ç´¢å™¨ (Retriever) å·²å‡†å¤‡å°±ç»ªã€‚\n"
     ]
    }
   ],
   "source": [
    "# ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„åº“\n",
    "# !pip install langchain langchain-community langchain-text-splitters chromadb dashscope\n",
    "\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "import uuid\n",
    "\n",
    "# --- 1. é…ç½®åµŒå…¥æ¨¡å‹ (ä½¿ç”¨ DashScope APIï¼Œé¿å…ä¸‹è½½ HuggingFace æ¨¡å‹) ---\n",
    "try:\n",
    "    # ä½¿ç”¨æ‚¨å·²æœ‰çš„ DashScope API Key\n",
    "    embed_model = DashScopeEmbeddings(\n",
    "        model=\"text-embedding-v2\",\n",
    "        dashscope_api_key=\"sk-29e724dbecc44ac39f8932e356d4ea16\"\n",
    "    )\n",
    "    # æµ‹è¯•åµŒå…¥æ¨¡å‹æ˜¯å¦å·¥ä½œ\n",
    "    test_embedding = embed_model.embed_query(\"æµ‹è¯•æ–‡æœ¬\")\n",
    "    print(f\"âœ… ä½¿ç”¨ DashScope åµŒå…¥æ¨¡å‹: 'text-embedding-v2'\")\n",
    "    print(f\"   åµŒå…¥å‘é‡ç»´åº¦: {len(test_embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŠ è½½ DashScope åµŒå…¥æ¨¡å‹å¤±è´¥ã€‚é”™è¯¯: {e}\")\n",
    "    print(\"   è¯·ç¡®ä¿å·²å®‰è£… dashscope: pip install dashscope\")\n",
    "    embed_model = None\n",
    "\n",
    "# --- 2. åˆ‡åˆ†æ–‡æ¡£ ---\n",
    "if documents and embed_model:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=30)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    print(f\"âœ… æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(docs)} ä¸ªæ–‡æœ¬å—ã€‚\")\n",
    "\n",
    "    # --- 3. å‘é‡åŒ–å¹¶å­˜å…¥ ChromaDBï¼ŒåŒæ—¶åœ¨ MySQL ä¸­è®°å½•ç´¢å¼• ---\n",
    "    persist_directory = 'chroma_db_langchain'\n",
    "    \n",
    "    # ä¸ºæ¯ä¸ªæ–‡æ¡£å—ç”Ÿæˆå”¯ä¸€çš„ID\n",
    "    ids = [str(uuid.uuid4()) for _ in docs]\n",
    "    \n",
    "    # ä½¿ç”¨ from_documents ä¸€æ­¥å®ŒæˆåµŒå…¥å’Œå­˜å‚¨\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=docs, \n",
    "        embedding=embed_model,\n",
    "        ids=ids,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    print(f\"âœ… æ–‡æœ¬å—å·²å‘é‡åŒ–å¹¶å­˜å…¥ ChromaDBã€‚æ•°æ®åº“ä½ç½®: '{os.path.abspath(persist_directory)}'\")\n",
    "\n",
    "    # --- 4. å°†æ–‡ä»¶åå’Œå‘é‡IDçš„æ˜ å°„å…³ç³»å­˜å…¥ MySQL ---\n",
    "    if engine:\n",
    "        # å…ˆåˆ›å»ºè¡¨\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                create_table_sql = text(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS file_vector_index (\n",
    "                    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                    file_name VARCHAR(255) NOT NULL,\n",
    "                    vector_id VARCHAR(255) NOT NULL,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    INDEX idx_file_name (file_name),\n",
    "                    INDEX idx_vector_id (vector_id)\n",
    "                );\n",
    "                \"\"\")\n",
    "                connection.execute(create_table_sql)\n",
    "                connection.commit()\n",
    "                print(\"âœ… æ–‡ä»¶-å‘é‡ç´¢å¼•è¡¨ 'file_vector_index' å·²æˆåŠŸåˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ åˆ›å»º 'file_vector_index' è¡¨å¤±è´¥: {e}\")\n",
    "\n",
    "        # å†™å…¥æ˜ å°„æ•°æ®\n",
    "        mappings = []\n",
    "        for i, doc in enumerate(docs):\n",
    "            file_name = doc.metadata.get('source', 'unknown')\n",
    "            vector_id = ids[i]\n",
    "            mappings.append({'file_name': file_name, 'vector_id': vector_id})\n",
    "        \n",
    "        if mappings:\n",
    "            try:\n",
    "                with engine.connect() as connection:\n",
    "                    connection.execute(text(\"INSERT INTO file_vector_index (file_name, vector_id) VALUES (:file_name, :vector_id)\"), mappings)\n",
    "                    connection.commit()\n",
    "                    print(f\"âœ… æˆåŠŸå°† {len(mappings)} æ¡æ–‡ä»¶-å‘é‡æ˜ å°„å…³ç³»å†™å…¥ MySQL 'file_vector_index' è¡¨ã€‚\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ å†™å…¥ MySQL ç´¢å¼•è¡¨å¤±è´¥: {e}\")\n",
    "    \n",
    "    # å®šä¹‰ä¸€ä¸ª retriever ä»¥ä¾¿åç»­æ­¥éª¤ä½¿ç”¨\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "    print(\"âœ… æ£€ç´¢å™¨ (Retriever) å·²å‡†å¤‡å°±ç»ªã€‚\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ æ–‡æ¡£æˆ–åµŒå…¥æ¨¡å‹æœªå‡†å¤‡å¥½ï¼Œè·³è¿‡å‘é‡åŒ–å…¥åº“ã€‚\")\n",
    "    vectordb = None\n",
    "    retriever = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48108b27",
   "metadata": {},
   "source": [
    "## 6. æ··åˆæœç´¢ï¼šå®ç° Text2SQL + RAG\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ•´åˆæ‰€æœ‰éƒ¨åˆ†ï¼Œåˆ›å»ºä¸€ä¸ªå¼ºå¤§çš„æ··åˆæœç´¢å‡½æ•° `hybrid_ask`ã€‚å½“ç”¨æˆ·æé—®æ—¶ï¼Œæ­¤å‡½æ•°å°†ï¼š\n",
    "1.  **å¹¶è¡Œæ‰§è¡Œ Text2SQL**: å°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œä» MySQL æ•°æ®åº“ä¸­è·å–ç»“æ„åŒ–æ•°æ®ã€‚\n",
    "2.  **å¹¶è¡Œæ‰§è¡Œå‘é‡æ£€ç´¢**: ä» ChromaDB ä¸­æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„éç»“æ„åŒ–æ–‡æ¡£ï¼ˆæ•™å­¦æ”¿ç­–ã€è¯¾ç¨‹å¤§çº²ç­‰ï¼‰ã€‚\n",
    "3.  **LLM ç»¼åˆå›ç­”**: å°†ä¸Šè¿°ä¸¤éƒ¨åˆ†ç»“æœæ±‡æ€»ï¼Œäº¤ç»™ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥ç”Ÿæˆæœ€ç»ˆçš„ã€å…¨é¢çš„ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eefdd682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¤ç”¨å·²æœ‰çš„ DashScope clientã€‚\n",
      "\n",
      "==============================\n",
      "æ··åˆæœç´¢ç¤ºä¾‹ (ä½¿ç”¨æ¨¡å‹: qwen-turbo)\n",
      "==============================\n",
      "\n",
      "ğŸ” æ­£åœ¨è¿›è¡Œå‘é‡æ£€ç´¢...\n",
      "  - RAG ä¸Šä¸‹æ–‡è·å–å®Œæ¯•ã€‚\n",
      "ğŸ” æ­£åœ¨ç”Ÿæˆå¹¶æ‰§è¡Œ SQL æŸ¥è¯¢...\n",
      "  - ç”Ÿæˆçš„ SQL: \n",
      "SELECT course.credits  \n",
      "FROM course  \n",
      "JOIN teaches ON course.course_id = teaches.course_id  \n",
      "JOIN instructor ON teaches.ID = instructor.ID  \n",
      "WHERE instructor.name = 'Lembr';\n",
      "  - SQL ç»“æœ: \n",
      "æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° 2 æ¡è®°å½•ï¼š\n",
      " credits\n",
      "     4.0\n",
      "     4.0\n",
      "\n",
      "ğŸ¤– æ­£åœ¨ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...\n",
      "\n",
      "--- æœ€ç»ˆç­”æ¡ˆ ---\n",
      "æŸ¥è¯¢åˆ°ä¸»è®²è€å¸ˆä¸º 'Lembr' çš„è¯¾ç¨‹çš„å­¦åˆ†ä¸º 4.0ã€‚\n"
     ]
    }
   ],
   "source": [
    "# --- 0. æ£€æŸ¥ LLM å®¢æˆ·ç«¯ ---\n",
    "# æˆ‘ä»¬å°†ç›´æ¥ä½¿ç”¨æ‚¨åœ¨ 'æˆ‘çš„æ±‡æ€»å¤‡ä»½.ipynb' ä¸­å®šä¹‰çš„å…¨å±€ client\n",
    "# å®ƒå·²ç»é…ç½®å¥½äº† DashScope çš„ API Key å’Œ Base URL\n",
    "if 'client' not in locals() or client is None:\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI(\n",
    "            api_key=\"sk-29e724dbecc44ac39f8932e356d4ea16\",\n",
    "            base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "        )\n",
    "        print(\"âœ… å·²æ ¹æ®æ‚¨çš„é£æ ¼åˆå§‹åŒ– DashScope clientã€‚\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆå§‹åŒ– DashScope client å¤±è´¥: {e}\")\n",
    "        client = None\n",
    "else:\n",
    "    print(\"âœ… å¤ç”¨å·²æœ‰çš„ DashScope clientã€‚\")\n",
    "\n",
    "# --- é…ç½®ä½¿ç”¨çš„æ¨¡å‹ ---\n",
    "# qwen-plus å…è´¹é¢åº¦ç”¨å®Œåï¼Œå¯ä»¥æ”¹ç”¨ qwen-turboï¼ˆæ›´ä¾¿å®œ/å…è´¹é¢åº¦æ›´å¤šï¼‰\n",
    "LLM_MODEL = \"qwen-turbo\"  # å¯é€‰: \"qwen-plus\", \"qwen-turbo\", \"qwen-max\"\n",
    "\n",
    "# --- 1. åˆ›å»º Text2SQL å·¥å…· (é£æ ¼å¯¹é½) ---\n",
    "def get_schema(engine):\n",
    "    \"\"\"è·å–æ•°æ®åº“çš„ schema ä¿¡æ¯\"\"\"\n",
    "    try:\n",
    "        with open(\"backend/college_db_schema.txt\", \"r\") as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"é”™è¯¯ï¼šæ‰¾ä¸åˆ° schema æ–‡ä»¶ã€‚\"\n",
    "\n",
    "def run_sql(query: str):\n",
    "    \"\"\"æ‰§è¡Œ SQL æŸ¥è¯¢å¹¶è¿”å›ç»“æœï¼ˆæ ¼å¼åŒ–ä¸ºæ›´æ˜“è¯»çš„å½¢å¼ï¼‰\"\"\"\n",
    "    if not engine:\n",
    "        return \"æ•°æ®åº“æœªè¿æ¥ã€‚\"\n",
    "    try:\n",
    "        # æ¸…ç† SQL æŸ¥è¯¢ï¼Œç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°å’Œæ³¨é‡Š\n",
    "        clean_query = query.strip()\n",
    "        if clean_query.startswith(\"```sql\"):\n",
    "            clean_query = clean_query[6:]\n",
    "        if clean_query.startswith(\"```\"):\n",
    "            clean_query = clean_query[3:]\n",
    "        if clean_query.endswith(\"```\"):\n",
    "            clean_query = clean_query[:-3]\n",
    "        clean_query = clean_query.strip()\n",
    "        \n",
    "        # ç§»é™¤ SQL æ³¨é‡Šï¼ˆ-- å¼€å¤´çš„è¡Œï¼‰\n",
    "        lines = clean_query.split('\\n')\n",
    "        clean_lines = [line for line in lines if not line.strip().startswith('--')]\n",
    "        clean_query = '\\n'.join(clean_lines).strip()\n",
    "        \n",
    "        # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè¿”å›æç¤º\n",
    "        if not clean_query:\n",
    "            return \"æ— æœ‰æ•ˆçš„ SQL æŸ¥è¯¢ã€‚\"\n",
    "        \n",
    "        with engine.connect() as connection:\n",
    "            df = pd.read_sql(text(clean_query), connection)\n",
    "            \n",
    "            # æ”¹è¿›è¾“å‡ºæ ¼å¼ï¼Œä½¿ LLM æ›´å®¹æ˜“ç†è§£\n",
    "            if df.empty:\n",
    "                return \"æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œæ•°æ®åº“ä¸­æ²¡æœ‰åŒ¹é…çš„è®°å½•ã€‚\"\n",
    "            \n",
    "            # æ ¼å¼åŒ–è¾“å‡ºï¼šæ˜ç¡®è¯´æ˜æŸ¥è¯¢åˆ°äº†å¤šå°‘æ¡è®°å½•\n",
    "            result_lines = [f\"æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•ï¼š\"]\n",
    "            result_lines.append(df.to_string(index=False))\n",
    "            return \"\\n\".join(result_lines)\n",
    "    except Exception as e:\n",
    "        return f\"SQL æ‰§è¡Œé”™è¯¯: {e}\"\n",
    "\n",
    "def generate_sql_from_question(question: str, db_schema: str):\n",
    "    \"\"\"ä½¿ç”¨æ‚¨çš„ client é£æ ¼ï¼Œå°†é—®é¢˜è½¬æ¢ä¸º SQL\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    æ ¹æ®ä¸‹é¢çš„æ•°æ®åº“è¡¨ç»“æ„ï¼Œå°†ç”¨æˆ·çš„é—®é¢˜è½¬æ¢ä¸ºä¸€ä¸ª SQL æŸ¥è¯¢ã€‚\n",
    "    \n",
    "    é‡è¦è§„åˆ™ï¼š\n",
    "    1. åªè¿”å› SQL æŸ¥è¯¢è¯­å¥ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–è§£é‡Šæˆ–æ³¨é‡Š\n",
    "    2. å¦‚æœé—®é¢˜åŒ…å«å¤šä¸ªéƒ¨åˆ†ï¼Œåªå¤„ç†èƒ½ç”¨ SQL æŸ¥è¯¢çš„éƒ¨åˆ†\n",
    "    3. æ³¨æ„è¡¨ä¹‹é—´çš„æ­£ç¡®å…³è”å…³ç³»ï¼š\n",
    "       - instructor é€šè¿‡ teaches è¡¨ä¸ course å…³è”\n",
    "       - teaches è¡¨åŒ…å« (ID, course_id, sec_id, semester, year)\n",
    "       - course è¡¨åŒ…å« (course_id, title, dept_name, credits)\n",
    "       - instructor è¡¨åŒ…å« (ID, name, dept_name, salary)\n",
    "\n",
    "    æ•°æ®åº“è¡¨ç»“æ„:\n",
    "    {db_schema}\n",
    "\n",
    "    ç”¨æˆ·é—®é¢˜: {question}\n",
    "\n",
    "    SQL æŸ¥è¯¢:\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --- 2. å®ç° hybrid_ask å‡½æ•° (é£æ ¼å¯¹é½) ---\n",
    "def hybrid_ask(question: str):\n",
    "    if not client or not retriever or not engine:\n",
    "        print(\"âš ï¸ ç³»ç»Ÿæœªå®Œå…¨åˆå§‹åŒ– (Client, Retriever, æˆ– Engine æœªå‡†å¤‡å¥½)ã€‚\")\n",
    "        return\n",
    "\n",
    "    # -- æ­¥éª¤ A: å¹¶è¡Œè·å–ä¸Šä¸‹æ–‡ --\n",
    "    \n",
    "    # A.1: RAG æ£€ç´¢éç»“æ„åŒ–æ–‡æ¡£\n",
    "    print(\"ğŸ” æ­£åœ¨è¿›è¡Œå‘é‡æ£€ç´¢...\")\n",
    "    rag_docs = retriever.invoke(question)\n",
    "    rag_context = \"\\n\\n\".join([doc.page_content for doc in rag_docs])\n",
    "    print(\"  - RAG ä¸Šä¸‹æ–‡è·å–å®Œæ¯•ã€‚\")\n",
    "\n",
    "    # A.2: Text2SQL è·å–ç»“æ„åŒ–æ•°æ®\n",
    "    print(\"ğŸ” æ­£åœ¨ç”Ÿæˆå¹¶æ‰§è¡Œ SQL æŸ¥è¯¢...\")\n",
    "    db_schema = get_schema(engine)\n",
    "    generated_sql = generate_sql_from_question(question, db_schema)\n",
    "    print(f\"  - ç”Ÿæˆçš„ SQL: \\n{generated_sql}\")\n",
    "    sql_results = run_sql(generated_sql)\n",
    "    print(f\"  - SQL ç»“æœ: \\n{sql_results}\")\n",
    "\n",
    "    # -- æ­¥éª¤ B: LLM ç»¼åˆå›ç­” --\n",
    "    # æ”¹è¿›æç¤ºè¯ï¼Œæ˜ç¡®å‘Šè¯‰ LLM å¦‚ä½•ä½¿ç”¨æ•°æ®åº“æŸ¥è¯¢ç»“æœ\n",
    "    final_prompt = f\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™åŠ¡ç³»ç»Ÿé—®ç­”åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå…¨é¢è€Œå‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
    "\n",
    "    **ç”¨æˆ·é—®é¢˜:**\n",
    "    {question}\n",
    "\n",
    "    ---\n",
    "    **ç›¸å…³æ–‡æ¡£ä¿¡æ¯ (æ¥è‡ªæ•™å­¦æ”¿ç­–ã€è¯¾ç¨‹å¤§çº²ç­‰):**\n",
    "    {rag_context}\n",
    "    ---\n",
    "    **æ•°æ®åº“æŸ¥è¯¢ç»“æœ (è¿™æ˜¯ä»æ•™åŠ¡æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°çš„çœŸå®æ•°æ®ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨è¿™äº›æ•°æ®å›ç­”é—®é¢˜):**\n",
    "    {sql_results}\n",
    "    ---\n",
    "\n",
    "    **å›ç­”è¦æ±‚:**\n",
    "    1. å¦‚æœæ•°æ®åº“æŸ¥è¯¢ç»“æœåŒ…å«æœ‰æ•ˆæ•°æ®ï¼Œè¯·ç›´æ¥ä½¿ç”¨è¿™äº›æ•°æ®å›ç­”é—®é¢˜\n",
    "    2. å¦‚æœæ•°æ®åº“æŸ¥è¯¢ç»“æœä¸ºç©ºæˆ–å‡ºé”™ï¼Œå†è€ƒè™‘ä»æ–‡æ¡£ä¿¡æ¯ä¸­å¯»æ‰¾ç­”æ¡ˆ\n",
    "    3. å›ç­”è¦ç®€æ´ã€å‡†ç¡®ï¼Œç›´æ¥ç»™å‡ºæŸ¥è¯¢åˆ°çš„å…·ä½“æ•°å€¼æˆ–ä¿¡æ¯\n",
    "\n",
    "    **ä½ çš„ç»¼åˆå›ç­”:**\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ¤– æ­£åœ¨ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...\")\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": final_prompt}]\n",
    "    )\n",
    "    final_answer = final_response.choices[0].message.content\n",
    "    \n",
    "    return final_answer\n",
    "\n",
    "# --- 3. è¿è¡Œç¤ºä¾‹ ---\n",
    "if client:\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"æ··åˆæœç´¢ç¤ºä¾‹ (ä½¿ç”¨æ¨¡å‹: {LLM_MODEL})\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "    \n",
    "    # ç¤ºä¾‹é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜å¯èƒ½éœ€è¦ç»“åˆæ•°æ®åº“å’Œæ–‡æ¡£æ‰èƒ½å®Œç¾å›ç­”\n",
    "    example_question = \"æŸ¥è¯¢ä¸»è®²è€å¸ˆä¸º 'Lembr' çš„è¯¾ç¨‹çš„å­¦åˆ†æ˜¯å¤šå°‘ï¼Ÿ\"\n",
    "    \n",
    "    final_answer = hybrid_ask(example_question)\n",
    "    \n",
    "    print(\"\\n--- æœ€ç»ˆç­”æ¡ˆ ---\")\n",
    "    print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e577f9",
   "metadata": {},
   "source": [
    "## 7. ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "\n",
    "æœ€åï¼Œä¸ºäº†é‡åŒ–æˆ‘ä»¬çš„ä¼˜åŒ–æ•ˆæœï¼Œæˆ‘ä»¬éœ€è¦å»ºç«‹ä¸€ä¸ªç®€å•çš„åŸºå‡†æµ‹è¯•æ¡†æ¶ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- **åˆ›å»ºè¯„ä¼°é›†**: å‡†å¤‡ä¸€ä¸ªåŒ…å«å¤šä¸ªä»£è¡¨æ€§é—®é¢˜å’Œå…¶\"é»„é‡‘æ ‡å‡†\"ç­”æ¡ˆï¼ˆæˆ–æœŸæœ›åŒ…å«çš„å…³é”®è¯ï¼‰çš„è¯„ä¼°é›†ã€‚\n",
    "- **å®šä¹‰è¯„ä¼°æŒ‡æ ‡**:\n",
    "    - **å“åº”æ—¶é—´**: ä»æé—®åˆ°è·å¾—æœ€ç»ˆç­”æ¡ˆçš„æ€»æ—¶é—´ã€‚\n",
    "    - **æ£€ç´¢å‡†ç¡®ç‡ (Hit Rate)**: æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦åŒ…å«äº†ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆæ‰€éœ€çš„ä¿¡æ¯ã€‚\n",
    "    - **ç­”æ¡ˆè´¨é‡**: ï¼ˆä¸»è§‚æˆ–ä½¿ç”¨ LLM-as-a-judgeï¼‰ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯å¦å‡†ç¡®ã€å®Œæ•´ã€‚\n",
    "- **æ‰§è¡ŒåŸºå‡†æµ‹è¯•**: åˆ†åˆ«åœ¨ä¼˜åŒ–å‰å’Œä¼˜åŒ–åçš„ç³»ç»Ÿä¸Šè¿è¡Œè¯„ä¼°é›†ï¼Œå¹¶è®°å½•å„é¡¹æŒ‡æ ‡ï¼Œè¿›è¡Œå¯¹æ¯”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c52c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- è¿è¡Œæ··åˆæœç´¢ç³»ç»ŸåŸºå‡†æµ‹è¯• ---\n",
      "ğŸ” æ­£åœ¨è¿›è¡Œå‘é‡æ£€ç´¢...\n",
      "  - RAG ä¸Šä¸‹æ–‡è·å–å®Œæ¯•ã€‚\n",
      "ğŸ” æ­£åœ¨ç”Ÿæˆå¹¶æ‰§è¡Œ SQL æŸ¥è¯¢...\n",
      "  - ç”Ÿæˆçš„ SQL: \n",
      "SELECT course.title  \n",
      "FROM course  \n",
      "JOIN teaches ON course.course_id = teaches.course_id  \n",
      "JOIN instructor ON teaches.ID = instructor.ID  \n",
      "WHERE instructor.name = 'Romero';\n",
      "  - SQL ç»“æœ: \n",
      "æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° 4 æ¡è®°å½•ï¼š\n",
      "                      title\n",
      "           Image Processing\n",
      "           Image Processing\n",
      "International Communication\n",
      "                 Journalism\n",
      "\n",
      "ğŸ¤– æ­£åœ¨ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...\n",
      "ğŸ” æ­£åœ¨è¿›è¡Œå‘é‡æ£€ç´¢...\n",
      "  - RAG ä¸Šä¸‹æ–‡è·å–å®Œæ¯•ã€‚\n",
      "ğŸ” æ­£åœ¨ç”Ÿæˆå¹¶æ‰§è¡Œ SQL æŸ¥è¯¢...\n",
      "  - ç”Ÿæˆçš„ SQL: \n",
      "SELECT i.name\n",
      "FROM instructor i\n",
      "JOIN teaches t ON i.ID = t.ID\n",
      "JOIN course c ON t.course_id = c.course_id\n",
      "WHERE c.title = 'Manufacturing';\n",
      "  - SQL ç»“æœ: \n",
      "æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° 1 æ¡è®°å½•ï¼š\n",
      "  name\n",
      "Mingoz\n",
      "\n",
      "ğŸ¤– æ­£åœ¨ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...\n",
      "ğŸ” æ­£åœ¨è¿›è¡Œå‘é‡æ£€ç´¢...\n",
      "  - RAG ä¸Šä¸‹æ–‡è·å–å®Œæ¯•ã€‚\n",
      "ğŸ” æ­£åœ¨ç”Ÿæˆå¹¶æ‰§è¡Œ SQL æŸ¥è¯¢...\n",
      "  - ç”Ÿæˆçš„ SQL: \n",
      "SELECT * FROM course WHERE title = 'å­¦æœ¯è¯šä¿¡';\n",
      "  - SQL ç»“æœ: \n",
      "æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œæ•°æ®åº“ä¸­æ²¡æœ‰åŒ¹é…çš„è®°å½•ã€‚\n",
      "\n",
      "ğŸ¤– æ­£åœ¨ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...\n",
      "ğŸ” æ­£åœ¨è¿›è¡Œå‘é‡æ£€ç´¢...\n",
      "  - RAG ä¸Šä¸‹æ–‡è·å–å®Œæ¯•ã€‚\n",
      "ğŸ” æ­£åœ¨ç”Ÿæˆå¹¶æ‰§è¡Œ SQL æŸ¥è¯¢...\n",
      "  - ç”Ÿæˆçš„ SQL: \n",
      "SELECT course.credits\n",
      "FROM course\n",
      "JOIN teaches ON course.course_id = teaches.course_id\n",
      "JOIN instructor ON teaches.ID = instructor.ID\n",
      "WHERE instructor.name = 'Lembr';\n",
      "  - SQL ç»“æœ: \n",
      "æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° 2 æ¡è®°å½•ï¼š\n",
      " credits\n",
      "     4.0\n",
      "     4.0\n",
      "\n",
      "ğŸ¤– æ­£åœ¨ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...\n",
      "\n",
      "--- åŸºå‡†æµ‹è¯•å®Œæˆ ---\n",
      "å¹³å‡å“åº”æ—¶é—´: 1.1876 ç§’\n",
      "å‘½ä¸­ç‡ (Hit Rate): 100.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>latency</th>\n",
       "      <th>is_hit</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æŸ¥è¯¢ä¸»è®²è€å¸ˆä¸º 'Romero' çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿ</td>\n",
       "      <td>1.290928</td>\n",
       "      <td>True</td>\n",
       "      <td>æŸ¥è¯¢åˆ°ä¸»è®²è€å¸ˆä¸º 'Romero' çš„è¯¾ç¨‹åç§°æ˜¯ï¼šImage Processingã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manufacturing è¿™é—¨è¯¾ç¨‹çš„æˆè¯¾è€å¸ˆæ˜¯è°ï¼Ÿ</td>\n",
       "      <td>1.188208</td>\n",
       "      <td>True</td>\n",
       "      <td>Manufacturing è¿™é—¨è¯¾ç¨‹çš„æˆè¯¾è€å¸ˆæ˜¯ Mingozã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>å…³äºå­¦æœ¯è¯šä¿¡æœ‰ä»€ä¹ˆè§„å®šï¼Ÿ</td>\n",
       "      <td>1.098287</td>\n",
       "      <td>True</td>\n",
       "      <td>æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ•™å­¦æ”¿ç­–ä¸­æåˆ°æ‰€æœ‰å­¦ç”Ÿå¿…é¡»éµå®ˆå­¦æœ¯è¯šä¿¡åŸåˆ™ï¼Œä¸¥ç¦æŠ„è¢­ã€‚å…³äºæ›´è¯¦ç»†çš„å­¦æœ¯è¯šä¿¡è§„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æŸ¥è¯¢ 'Lembr' è€å¸ˆæ•™æˆçš„è¯¾ç¨‹å­¦åˆ†æ˜¯å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>1.172883</td>\n",
       "      <td>True</td>\n",
       "      <td>'Lembr' è€å¸ˆæ•™æˆçš„è¯¾ç¨‹å­¦åˆ†æ˜¯ 4.0ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     question   latency  is_hit  \\\n",
       "0  æŸ¥è¯¢ä¸»è®²è€å¸ˆä¸º 'Romero' çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿ  1.290928    True   \n",
       "1  Manufacturing è¿™é—¨è¯¾ç¨‹çš„æˆè¯¾è€å¸ˆæ˜¯è°ï¼Ÿ  1.188208    True   \n",
       "2                å…³äºå­¦æœ¯è¯šä¿¡æœ‰ä»€ä¹ˆè§„å®šï¼Ÿ  1.098287    True   \n",
       "3    æŸ¥è¯¢ 'Lembr' è€å¸ˆæ•™æˆçš„è¯¾ç¨‹å­¦åˆ†æ˜¯å¤šå°‘ï¼Ÿ  1.172883    True   \n",
       "\n",
       "                                            response  \n",
       "0         æŸ¥è¯¢åˆ°ä¸»è®²è€å¸ˆä¸º 'Romero' çš„è¯¾ç¨‹åç§°æ˜¯ï¼šImage Processingã€‚  \n",
       "1                   Manufacturing è¿™é—¨è¯¾ç¨‹çš„æˆè¯¾è€å¸ˆæ˜¯ Mingozã€‚  \n",
       "2  æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ•™å­¦æ”¿ç­–ä¸­æåˆ°æ‰€æœ‰å­¦ç”Ÿå¿…é¡»éµå®ˆå­¦æœ¯è¯šä¿¡åŸåˆ™ï¼Œä¸¥ç¦æŠ„è¢­ã€‚å…³äºæ›´è¯¦ç»†çš„å­¦æœ¯è¯šä¿¡è§„...  \n",
       "3                            'Lembr' è€å¸ˆæ•™æˆçš„è¯¾ç¨‹å­¦åˆ†æ˜¯ 4.0ã€‚  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# --- 1. å®šä¹‰è¯„ä¼°é›† (ä½¿ç”¨æ•°æ®åº“ä¸­çœŸå®å­˜åœ¨çš„æ•°æ®) ---\n",
    "# åŸºäºæ•°æ®åº“å®é™…æ•°æ®ï¼š\n",
    "# - æ•™å¸ˆ: Lembr, Bawa, Yazdi, Wieland, Romero, Mingoz, Dale ç­‰\n",
    "# - è¯¾ç¨‹: Image Processing, Manufacturing, Elastic Structures, Accounting ç­‰\n",
    "# - å…³è”: Romero æ•™ Image Processing, Mingoz æ•™ Manufacturing ç­‰\n",
    "\n",
    "eval_questions = [\n",
    "    {\n",
    "        \"question\": \"æŸ¥è¯¢ä¸»è®²è€å¸ˆä¸º 'Romero' çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "        \"expected_keywords\": [\"Image Processing\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Manufacturing è¿™é—¨è¯¾ç¨‹çš„æˆè¯¾è€å¸ˆæ˜¯è°ï¼Ÿ\",\n",
    "        \"expected_keywords\": [\"Mingoz\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"å…³äºå­¦æœ¯è¯šä¿¡æœ‰ä»€ä¹ˆè§„å®šï¼Ÿ\",\n",
    "        \"expected_keywords\": [\"å­¦æœ¯è¯šä¿¡\", \"æŠ„è¢­\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"æŸ¥è¯¢ 'Lembr' è€å¸ˆæ•™æˆçš„è¯¾ç¨‹å­¦åˆ†æ˜¯å¤šå°‘ï¼Ÿ\",\n",
    "        \"expected_keywords\": [\"4\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "# --- 2. å®šä¹‰è¯„ä¼°å‡½æ•° ---\n",
    "def run_benchmark(questions):\n",
    "    total_time = 0\n",
    "    hit_count = 0\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for item in questions:\n",
    "        q = item[\"question\"]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = hybrid_ask(q)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        latency = end_time - start_time\n",
    "        total_time += latency\n",
    "        \n",
    "        # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨å“åº”ä¸­\n",
    "        response_text = str(response) if response else \"\"\n",
    "        \n",
    "        is_hit = all(keyword in response_text for keyword in item[\"expected_keywords\"])\n",
    "        if is_hit:\n",
    "            hit_count += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"question\": q,\n",
    "            \"latency\": latency,\n",
    "            \"is_hit\": is_hit,\n",
    "            \"response\": response_text[:200] + \"...\" if len(response_text) > 200 else response_text\n",
    "        })\n",
    "\n",
    "    avg_latency = total_time / len(questions)\n",
    "    hit_rate = hit_count / len(questions)\n",
    "    \n",
    "    print(f\"\\n--- åŸºå‡†æµ‹è¯•å®Œæˆ ---\")\n",
    "    print(f\"å¹³å‡å“åº”æ—¶é—´: {avg_latency:.4f} ç§’\")\n",
    "    print(f\"å‘½ä¸­ç‡ (Hit Rate): {hit_rate:.2%}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- 3. è¿è¡Œæµ‹è¯• ---\n",
    "if client and retriever and engine:\n",
    "    print(\"\\n--- è¿è¡Œæ··åˆæœç´¢ç³»ç»ŸåŸºå‡†æµ‹è¯• ---\")\n",
    "    results_df = run_benchmark(eval_questions)\n",
    "    display(results_df)\n",
    "else:\n",
    "    print(\"âš ï¸ ç³»ç»Ÿæœªå®Œå…¨åˆå§‹åŒ–ï¼Œæ— æ³•è¿è¡ŒåŸºå‡†æµ‹è¯•ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45bab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# --- 1. å®šä¹‰è¯„ä¼°é›† ---\n",
    "eval_questions = [\n",
    "    {\n",
    "        \"question\": \"è®¡ç®—æœºç§‘å­¦å¯¼è®ºçš„æˆè¯¾è€å¸ˆæ˜¯è°ï¼Ÿ\",\n",
    "        \"expected_keywords\": [\"Alan Turing\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"CS101 è¯¾ç¨‹æ¶µç›–å“ªäº›ä¸»é¢˜ï¼Ÿ\",\n",
    "        \"expected_keywords\": [\"ç®—æ³•\", \"æ•°æ®ç»“æ„\", \"è®¡ç®—ç†è®º\"]\n",
    "    },\n",
    "    # ...å¯ä»¥æ·»åŠ æ›´å¤šé—®é¢˜\n",
    "]\n",
    "\n",
    "# --- 2. å®šä¹‰è¯„ä¼°å‡½æ•° ---\n",
    "def run_benchmark(query_engine, questions):\n",
    "    total_time = 0\n",
    "    hit_count = 0\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for item in questions:\n",
    "        q = item[\"question\"]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = query_engine.query(q)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        latency = end_time - start_time\n",
    "        total_time += latency\n",
    "        \n",
    "        # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨å“åº”æˆ–æºèŠ‚ç‚¹ä¸­\n",
    "        response_text = str(response)\n",
    "        source_text = \" \".join([node.get_content() for node in response.source_nodes])\n",
    "        \n",
    "        is_hit = all(keyword in (response_text + source_text) for keyword in item[\"expected_keywords\"])\n",
    "        if is_hit:\n",
    "            hit_count += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"question\": q,\n",
    "            \"latency\": latency,\n",
    "            \"is_hit\": is_hit,\n",
    "            \"response\": response_text\n",
    "        })\n",
    "\n",
    "    avg_latency = total_time / len(questions)\n",
    "    hit_rate = hit_count / len(questions)\n",
    "    \n",
    "    print(f\"\\n--- åŸºå‡†æµ‹è¯•å®Œæˆ ---\")\n",
    "    print(f\"å¹³å‡å“åº”æ—¶é—´: {avg_latency:.4f} ç§’\")\n",
    "    print(f\"å‘½ä¸­ç‡ (Hit Rate): {hit_rate:.2%}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- 3. è¿è¡Œæµ‹è¯• ---\n",
    "if 'base_query_engine' in locals() and base_query_engine:\n",
    "    print(\"\\n--- è¿è¡ŒåŸºç¡€ RAG ç³»ç»ŸåŸºå‡†æµ‹è¯• ---\")\n",
    "    base_results_df = run_benchmark(base_query_engine, eval_questions)\n",
    "    display(base_results_df)\n",
    "\n",
    "if 'rerank_query_engine' in locals() and rerank_query_engine:\n",
    "    print(\"\\n--- è¿è¡Œå¸¦é‡æ’å™¨çš„ RAG ç³»ç»ŸåŸºå‡†æµ‹è¯• ---\")\n",
    "    rerank_results_df = run_benchmark(rerank_query_engine, eval_questions)\n",
    "    display(rerank_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549521c",
   "metadata": {},
   "source": [
    "## 7. ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "\n",
    "æœ€åï¼Œä¸ºäº†é‡åŒ–æˆ‘ä»¬çš„ä¼˜åŒ–æ•ˆæœï¼Œæˆ‘ä»¬éœ€è¦å»ºç«‹ä¸€ä¸ªç®€å•çš„åŸºå‡†æµ‹è¯•æ¡†æ¶ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- **åˆ›å»ºè¯„ä¼°é›†**: å‡†å¤‡ä¸€ä¸ªåŒ…å«å¤šä¸ªä»£è¡¨æ€§é—®é¢˜å’Œå…¶â€œé»„é‡‘æ ‡å‡†â€ç­”æ¡ˆï¼ˆæˆ–æœŸæœ›åŒ…å«çš„å…³é”®è¯ï¼‰çš„è¯„ä¼°é›†ã€‚\n",
    "- **å®šä¹‰è¯„ä¼°æŒ‡æ ‡**:\n",
    "    - **å“åº”æ—¶é—´**: ä»æé—®åˆ°è·å¾—æœ€ç»ˆç­”æ¡ˆçš„æ€»æ—¶é—´ã€‚\n",
    "    - **æ£€ç´¢å‡†ç¡®ç‡ (Hit Rate)**: æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦åŒ…å«äº†ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆæ‰€éœ€çš„ä¿¡æ¯ã€‚\n",
    "    - **ç­”æ¡ˆè´¨é‡**: ï¼ˆä¸»è§‚æˆ–ä½¿ç”¨ LLM-as-a-judgeï¼‰ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯å¦å‡†ç¡®ã€å®Œæ•´ã€‚\n",
    "- **æ‰§è¡ŒåŸºå‡†æµ‹è¯•**: åˆ†åˆ«åœ¨ä¼˜åŒ–å‰å’Œä¼˜åŒ–åçš„ç³»ç»Ÿä¸Šè¿è¡Œè¯„ä¼°é›†ï¼Œå¹¶è®°å½•å„é¡¹æŒ‡æ ‡ï¼Œè¿›è¡Œå¯¹æ¯”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¡®ä¿å®‰è£…äº† cohere æˆ–å…¶ä»–é‡æ’å™¨åº“\n",
    "# !pip install llama-index-postprocessor-cohere\n",
    "\n",
    "from llama_index.core.postprocessor import CohereRerank\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "# --- 1. åŸºç¡€æ£€ç´¢ (æ— é‡æ’å™¨) ---\n",
    "if index:\n",
    "    # åˆ›å»ºä¸€ä¸ªåŸºç¡€çš„ Top-K æ£€ç´¢å™¨\n",
    "    base_retriever = VectorIndexRetriever(\n",
    "        index=index,\n",
    "        similarity_top_k=10,  # æ£€ç´¢10ä¸ªå€™é€‰æ–‡æ¡£\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºæŸ¥è¯¢å¼•æ“\n",
    "    base_query_engine = RetrieverQueryEngine.from_args(base_retriever)\n",
    "\n",
    "    query = \"è®¡ç®—æœºç§‘å­¦å¯¼è®ºçš„æˆè¯¾è€å¸ˆæ˜¯è°ï¼Ÿ\"\n",
    "    print(f\"--- â“ æŸ¥è¯¢: {query} ---\")\n",
    "    \n",
    "    print(\"\\n--- åŸºç¡€æ£€ç´¢ç»“æœ (æ— é‡æ’å™¨) ---\")\n",
    "    response_base = base_query_engine.query(query)\n",
    "    print(response_base)\n",
    "    # for node in response_base.source_nodes:\n",
    "    #     print(f\"  - [Score: {node.score:.4f}] {node.text[:100]}...\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ ç´¢å¼•æœªåˆ›å»ºï¼Œè·³è¿‡æ­¤éƒ¨åˆ†ã€‚\")\n",
    "\n",
    "\n",
    "# --- 2. å¸¦é‡æ’å™¨çš„æ£€ç´¢ ---\n",
    "# éœ€è¦ Cohere API Keyï¼Œæˆ–è€…ä½ å¯ä»¥æ¢æˆå…¶ä»–å¼€æºé‡æ’å™¨\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\", None)\n",
    "\n",
    "if index and COHERE_API_KEY:\n",
    "    try:\n",
    "        # åˆ›å»º Cohere é‡æ’å™¨\n",
    "        reranker = CohereRerank(api_key=COHERE_API_KEY, top_n=3) # ä»10ä¸ªå€™é€‰è€…ä¸­é€‰å‡ºæœ€ç›¸å…³çš„3ä¸ª\n",
    "        \n",
    "        # åˆ›å»ºå¸¦é‡æ’å™¨çš„æŸ¥è¯¢å¼•æ“\n",
    "        rerank_query_engine = RetrieverQueryEngine.from_args(\n",
    "            base_retriever,\n",
    "            node_postprocessors=[reranker]\n",
    "        )\n",
    "\n",
    "        print(\"\\n--- é«˜çº§æ£€ç´¢ç»“æœ (å¸¦ Cohere é‡æ’å™¨) ---\")\n",
    "        response_rerank = rerank_query_engine.query(query)\n",
    "        print(response_rerank)\n",
    "        # for node in response_rerank.source_nodes:\n",
    "        #     print(f\"  - [Score: {node.score:.4f}] {node.text[:100]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ é…ç½®é‡æ’å™¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ä¾èµ–é¡¹: {e}\")\n",
    "elif index:\n",
    "    print(\"\\nâš ï¸ æœªæä¾› COHERE_API_KEYï¼Œè·³è¿‡é‡æ’å™¨æ¼”ç¤ºã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be436be",
   "metadata": {},
   "source": [
    "## 6. é«˜çº§ RAG æ£€ç´¢ç­–ç•¥ä¼˜åŒ–\n",
    "\n",
    "åŸºç¡€çš„å‘é‡æ£€ç´¢ï¼ˆTop-Kï¼‰å¯èƒ½ä¸è¶³ä»¥åº”å¯¹å¤æ‚æŸ¥è¯¢ã€‚ä¸ºäº†æé«˜æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥æ›´é«˜çº§çš„ç­–ç•¥ï¼Œå¦‚**æ··åˆæœç´¢ï¼ˆHybrid Searchï¼‰**æˆ–**é‡æ’å™¨ï¼ˆRe-rankerï¼‰**ã€‚\n",
    "\n",
    "- **æ··åˆæœç´¢**: ç»“åˆäº†**å‘é‡æœç´¢**ï¼ˆè¯­ä¹‰ç›¸å…³ï¼‰å’Œä¼ ç»Ÿçš„**å…³é”®è¯æœç´¢**ï¼ˆå¦‚ BM25ï¼Œç²¾ç¡®åŒ¹é…ï¼‰ã€‚è¿™å¯¹äºåŒ…å«ç‰¹å®šæœ¯è¯­æˆ–ä»£ç çš„æŸ¥è¯¢ç‰¹åˆ«æœ‰æ•ˆã€‚\n",
    "- **é‡æ’å™¨**: åœ¨è·å–åˆæ­¥çš„ Top-K æ£€ç´¢ç»“æœåï¼Œä½¿ç”¨ä¸€ä¸ªæ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆå¦‚ `Cross-Encoder`ï¼‰å¯¹è¿™äº›ç»“æœè¿›è¡Œé‡æ–°æ’åºï¼Œå°†æœ€ç›¸å…³çš„æ–‡æ¡£æ’åœ¨æœ€å‰é¢ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- å®ç°ä¸€ä¸ªå¸¦é‡æ’å™¨çš„æŸ¥è¯¢å¼•æ“ã€‚\n",
    "- å¯¹æ¯”æœ‰æ— é‡æ’å™¨æ—¶ï¼Œå¯¹äºåŒä¸€ä¸ªé—®é¢˜çš„æ£€ç´¢ç»“æœå’Œæœ€ç»ˆç­”æ¡ˆçš„è´¨é‡å·®å¼‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„åº“\n",
    "# !pip install llama-index-embeddings-huggingface\n",
    "# !pip install llama-index-vector-stores-chroma\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n",
    "\n",
    "# --- 1. é€‰æ‹©å’Œé…ç½®åµŒå…¥æ¨¡å‹ ---\n",
    "# ä½¿ç”¨ä¸€ä¸ªè½»é‡çº§çš„ã€é«˜è´¨é‡çš„å¼€æºæ¨¡å‹\n",
    "try:\n",
    "    embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    print(\"âœ… ä½¿ç”¨ HuggingFace åµŒå…¥æ¨¡å‹: 'sentence-transformers/all-MiniLM-L6-v2'\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŠ è½½åµŒå…¥æ¨¡å‹å¤±è´¥ã€‚è¯·ç¡®ä¿ 'sentence-transformers' å·²å®‰è£…ã€‚é”™è¯¯: {e}\")\n",
    "    embed_model = None\n",
    "\n",
    "# --- 2. é…ç½®å‘é‡å­˜å‚¨ (ChromaDB) ---\n",
    "# åˆ›å»ºä¸€ä¸ªæŒä¹…åŒ–çš„ ChromaDB å®¢æˆ·ç«¯\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"teaching_system_rag\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# --- 3. æ„å»ºæˆ–åŠ è½½ç´¢å¼• ---\n",
    "if documents and embed_model:\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    # ä½¿ç”¨ SentenceSplitter è¿›è¡Œåˆ†å—\n",
    "    splitter = SentenceSplitter(chunk_size=256, chunk_overlap=30)\n",
    "    \n",
    "    # æ„å»ºç´¢å¼•ã€‚è¿™ä¼šè‡ªåŠ¨å¤„ç†åˆ†å—ã€åµŒå…¥å’Œå­˜å‚¨\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context,\n",
    "        embed_model=embed_model,\n",
    "        transformations=[splitter]\n",
    "    )\n",
    "    print(\"âœ… ç´¢å¼•å·²æ„å»ºå¹¶å­˜å‚¨åœ¨ ChromaDB ä¸­ã€‚\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ–‡æ¡£æˆ–åµŒå…¥æ¨¡å‹æœªå‡†å¤‡å¥½ï¼Œè·³è¿‡ç´¢å¼•æ„å»ºã€‚\")\n",
    "    index = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6eaf2f",
   "metadata": {},
   "source": [
    "## 5. RAG ç®¡é“åˆ†æï¼šåµŒå…¥ä¸å‘é‡å­˜å‚¨\n",
    "\n",
    "åµŒå…¥æ¨¡å‹ï¼ˆEmbedding Modelï¼‰çš„è´¨é‡å’Œå‘é‡æ•°æ®åº“çš„æ•ˆç‡ç›´æ¥å½±å“æ£€ç´¢çš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- **è¯„ä¼°åµŒå…¥æ¨¡å‹**: å¦‚æœä½ ä½¿ç”¨çš„æ˜¯å¼€æºæ¨¡å‹ï¼ˆå¦‚ `sentence-transformers`ï¼‰ï¼Œå¯ä»¥è€ƒè™‘æ˜¯å¦æœ‰æ›´é€‚åˆç‰¹å®šé¢†åŸŸï¼ˆå¦‚æ•™è‚²ï¼‰çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚å¦‚æœä½ ä½¿ç”¨çš„æ˜¯å•†ä¸š APIï¼ˆå¦‚ OpenAIï¼‰ï¼Œæ£€æŸ¥æ¨¡å‹ç‰ˆæœ¬æ˜¯å¦æœ€æ–°ã€‚\n",
    "- **åˆ†æå‘é‡å­˜å‚¨**:\n",
    "    - **ç´¢å¼•ç±»å‹**: ä½ ä½¿ç”¨çš„æ˜¯ä»€ä¹ˆç´¢å¼•ï¼Ÿï¼ˆä¾‹å¦‚ï¼ŒFAISS çš„ `IndexFlatL2`ï¼ŒHNSW ç­‰ï¼‰ã€‚HNSW é€šå¸¸åœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¹‹é—´æœ‰å¾ˆå¥½çš„å¹³è¡¡ã€‚\n",
    "    - **è·ç¦»åº¦é‡**: ä½¿ç”¨çš„æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆ`cosine`ï¼‰è¿˜æ˜¯æ¬§æ°è·ç¦»ï¼ˆ`L2`ï¼‰ï¼Ÿå¯¹äºæ–‡æœ¬åµŒå…¥ï¼Œä½™å¼¦ç›¸ä¼¼åº¦é€šå¸¸æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚\n",
    "    - **å­˜å‚¨åç«¯**: ä½ çš„å‘é‡å­˜å‚¨æ˜¯å†…å­˜å‹çš„ï¼ˆå¦‚ FAISSï¼‰è¿˜æ˜¯æŒä¹…åŒ–çš„ï¼ˆå¦‚ Chroma, Qdrant, Milvusï¼‰ï¼Ÿå¯¹äºç”Ÿäº§ç³»ç»Ÿï¼ŒæŒä¹…åŒ–å­˜å‚¨æ˜¯å¿…éœ€çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42746c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¡®ä¿ä½ å·²ç»å®‰è£…äº† llama-index\n",
    "# !pip install llama-index\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "\n",
    "# --- 1. åŠ è½½æ–‡æ¡£ ---\n",
    "# å‡è®¾ä½ çš„æ–‡æ¡£å­˜å‚¨åœ¨ 'knowledge_base/docs' ç›®å½•ä¸‹\n",
    "DOCS_PATH = \"knowledge_base/docs\"\n",
    "if not os.path.exists(DOCS_PATH):\n",
    "    # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªå¹¶æ”¾å…¥ä¸€ä¸ªç¤ºä¾‹æ–‡æ¡£\n",
    "    os.makedirs(DOCS_PATH, exist_ok=True)\n",
    "    with open(os.path.join(DOCS_PATH, \"sample_syllabus.txt\"), \"w\") as f:\n",
    "        f.write(\"è¯¾ç¨‹: CS101, è®¡ç®—æœºç§‘å­¦å¯¼è®º. æˆè¯¾æ•™å¸ˆ: Alan Turing. æœ¬è¯¾ç¨‹æ¶µç›–ç®—æ³•ã€æ•°æ®ç»“æ„å’Œè®¡ç®—ç†è®ºçš„åŸºç¡€çŸ¥è¯†ã€‚\")\n",
    "\n",
    "try:\n",
    "    loader = SimpleDirectoryReader(DOCS_PATH)\n",
    "    documents = loader.load_data()\n",
    "    print(f\"âœ… æˆåŠŸä» '{DOCS_PATH}' åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£ã€‚\")\n",
    "    # print(\"ç¤ºä¾‹æ–‡æ¡£å†…å®¹:\", documents[0].text[:200], \"...\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŠ è½½æ–‡æ¡£å¤±è´¥: {e}\")\n",
    "    documents = []\n",
    "\n",
    "# --- 2. è¯•éªŒä¸åŒçš„åˆ†å—ç­–ç•¥ ---\n",
    "if documents:\n",
    "    text_sample = documents[0].text\n",
    "\n",
    "    # ç­–ç•¥ 1: è¾ƒå°çš„å—ï¼Œè¾ƒå¤§çš„é‡å \n",
    "    splitter_small = SentenceSplitter(chunk_size=128, chunk_overlap=20)\n",
    "    chunks_small = splitter_small.split_text(text_sample)\n",
    "    print(f\"\\n--- ç­–ç•¥ 1 (chunk_size=128, overlap=20) ---\")\n",
    "    print(f\"ç”Ÿæˆäº† {len(chunks_small)} ä¸ªå—ã€‚\")\n",
    "    # for i, chunk in enumerate(chunks_small):\n",
    "    #     print(f\"  å— {i+1}: '{chunk}'\")\n",
    "\n",
    "    # ç­–ç•¥ 2: è¾ƒå¤§çš„å—ï¼Œé€‚ä¸­çš„é‡å \n",
    "    splitter_large = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "    chunks_large = splitter_large.split_text(text_sample)\n",
    "    print(f\"\\n--- ç­–ç•¥ 2 (chunk_size=512, overlap=50) ---\")\n",
    "    print(f\"ç”Ÿæˆäº† {len(chunks_large)} ä¸ªå—ã€‚\")\n",
    "    # for i, chunk in enumerate(chunks_large):\n",
    "    #      print(f\"  å— {i+1}: '{chunk}'\")\n",
    "\n",
    "    # ç»“è®ºï¼šæ ¹æ®ä½ çš„æ–‡æ¡£ç‰¹æ€§é€‰æ‹©ã€‚å¯¹äºç»“æ„åŒ–çš„æ•™å­¦å¤§çº²ï¼Œè¾ƒå°çš„å—å¯èƒ½æ›´ç²¾ç¡®ï¼›\n",
    "    # å¯¹äºé•¿ç¯‡çš„è§„ç« åˆ¶åº¦ï¼Œè¾ƒå¤§çš„å—æ›´èƒ½ä¿æŒä¸Šä¸‹æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489d5fc",
   "metadata": {},
   "source": [
    "## 4. RAG ç®¡é“åˆ†æï¼šæ•°æ®åŠ è½½ä¸åˆ†å—\n",
    "\n",
    "RAG çš„æ€§èƒ½ä¸ä»…å–å†³äºæ•°æ®åº“ï¼Œè¿˜ä¸¥é‡ä¾èµ–äºè¾“å…¥æ–‡æ¡£çš„è´¨é‡å’Œå¤„ç†æ–¹å¼ã€‚æˆ‘ä»¬å°†é¦–å…ˆåˆ†ææ•°æ®åŠ è½½å’Œæ–‡æœ¬åˆ†å—ï¼ˆChunkingï¼‰ç­–ç•¥ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- ä½¿ç”¨ `SimpleDirectoryReader` (from `llama-index`) æˆ–ç±»ä¼¼å·¥å…·åŠ è½½ä½ çš„å¤šæ–‡ä»¶çŸ¥è¯†åº“ï¼ˆä¾‹å¦‚ï¼Œæ•™å­¦å¤§çº²ã€å­¦ç”Ÿæ‰‹å†Œç­‰ï¼‰ã€‚\n",
    "- è¯„ä¼°å½“å‰çš„æ–‡æœ¬åˆ†å—ç­–ç•¥ã€‚ä¸€ä¸ªå¥½çš„åˆ†å—ç­–ç•¥åº”åœ¨ä¿æŒè¯­ä¹‰å®Œæ•´æ€§å’Œé™åˆ¶å•å—å¤§å°ä¹‹é—´å–å¾—å¹³è¡¡ã€‚\n",
    "- è¯•éªŒä¸åŒçš„ `chunk_size` å’Œ `chunk_overlap` å€¼ï¼Œè§‚å¯Ÿå®ƒä»¬å¦‚ä½•å½±å“æ£€ç´¢ä¸Šä¸‹æ–‡çš„è´¨é‡ã€‚å¤ªå¤§çš„å—å¯èƒ½åŒ…å«è¿‡å¤šæ— å…³ä¿¡æ¯ï¼Œå¤ªå°çš„å—å¯èƒ½ä¸¢å¤±å…³é”®ä¸Šä¸‹æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_and_verify_index(index_creation_sql: str, query_to_re_analyze: str):\n",
    "    \"\"\"åº”ç”¨ç´¢å¼•å¹¶é‡æ–°åˆ†ææŸ¥è¯¢ä»¥éªŒè¯æ•ˆæœ\"\"\"\n",
    "    if not engine:\n",
    "        print(\"æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•æ‰§è¡Œæ“ä½œã€‚\")\n",
    "        return\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            # å¼€å§‹ä¸€ä¸ªäº‹åŠ¡\n",
    "            trans = connection.begin()\n",
    "            print(f\"ğŸš€ æ­£åœ¨å°è¯•åˆ›å»ºç´¢å¼•: {index_creation_sql}\")\n",
    "            connection.execute(text(index_creation_sql))\n",
    "            trans.commit()\n",
    "            print(\"âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸï¼ˆæˆ–å·²å­˜åœ¨ï¼‰ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ åˆ›å»ºç´¢å¼•æ—¶å‡ºç°é—®é¢˜ (å¯èƒ½æ˜¯ç´¢å¼•å·²å­˜åœ¨): {e}\")\n",
    "            if 'trans' in locals() and trans.is_active:\n",
    "                trans.rollback()\n",
    "\n",
    "    # å†æ¬¡åˆ†ææŸ¥è¯¢\n",
    "    print(\"\\n--- é‡æ–°åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ ---\")\n",
    "    analyze_query(query_to_re_analyze)\n",
    "\n",
    "# --- ç¤ºä¾‹ï¼šä¸º `course.title` å’Œ `department.building` åˆ›å»ºç´¢å¼• ---\n",
    "# æ³¨æ„ï¼šå¯¹äº LIKE '%...%' æŸ¥è¯¢ï¼ŒB-Tree ç´¢å¼•æ•ˆæœæœ‰é™ï¼Œä½†å¯¹äºå‰ç¼€åŒ¹é…æˆ–å…¨æ–‡ç´¢å¼•åˆ™éå¸¸æœ‰æ•ˆã€‚\n",
    "# è¿™é‡Œæˆ‘ä»¬ä»ç„¶åˆ›å»ºä¸€ä¸ªå¸¸è§„ç´¢å¼•ä½œä¸ºç¤ºä¾‹ã€‚\n",
    "index_sql_1 = \"CREATE INDEX idx_course_title ON course(title);\"\n",
    "index_sql_2 = \"CREATE INDEX idx_department_building ON department(building);\"\n",
    "\n",
    "# ä¸º course.title åˆ›å»ºç´¢å¼•å¹¶éªŒè¯\n",
    "apply_and_verify_index(index_sql_1, slow_query_example)\n",
    "\n",
    "# ä¸º department.building åˆ›å»ºç´¢å¼•å¹¶éªŒè¯\n",
    "apply_and_verify_index(index_sql_2, slow_query_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ab30a",
   "metadata": {},
   "source": [
    "## 3. æŸ¥è¯¢ä¼˜åŒ–ä¸ç´¢å¼•ç­–ç•¥\n",
    "\n",
    "æ ¹æ® `EXPLAIN` çš„åˆ†æç»“æœï¼Œæˆ‘ä»¬å¯ä»¥é‡‡å–æªæ–½ä¼˜åŒ–æŸ¥è¯¢ã€‚æœ€ç›´æ¥æœ‰æ•ˆçš„æ–¹æ³•æ˜¯ä¸ºæŸ¥è¯¢ä¸­ `WHERE` å­å¥å’Œ `JOIN` æ“ä½œæ¶‰åŠçš„åˆ—åˆ›å»ºç´¢å¼•ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- è¯†åˆ« `EXPLAIN` ç»“æœä¸­æœªä½¿ç”¨ç´¢å¼•çš„ `WHERE` æˆ– `JOIN` åˆ—ã€‚\n",
    "- ç¼–å†™ `CREATE INDEX` è¯­å¥ä¸ºè¿™äº›åˆ—æ·»åŠ ç´¢å¼•ã€‚\n",
    "- é‡æ–°è¿è¡Œ `EXPLAIN`ï¼ŒéªŒè¯æ–°ç´¢å¼•æ˜¯å¦è¢«æŸ¥è¯¢ä¼˜åŒ–å™¨ä½¿ç”¨ï¼ˆ`key` å­—æ®µåº”æ˜¾ç¤ºç´¢å¼•åç§°ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query(sql_query: str):\n",
    "    \"\"\"ä½¿ç”¨ EXPLAIN åˆ†æç»™å®šçš„ SQL æŸ¥è¯¢\"\"\"\n",
    "    if not engine:\n",
    "        print(\"æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•åˆ†ææŸ¥è¯¢ã€‚\")\n",
    "        return\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        # åœ¨æŸ¥è¯¢å‰åŠ ä¸Š EXPLAIN\n",
    "        explain_query = f\"EXPLAIN {sql_query}\"\n",
    "        try:\n",
    "            result = connection.execute(text(explain_query))\n",
    "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "            print(f\"ğŸ” å¯¹ä»¥ä¸‹æŸ¥è¯¢çš„ EXPLAIN åˆ†æç»“æœ:\")\n",
    "            print(f\"   '{sql_query}'\")\n",
    "            display(df)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ åˆ†ææŸ¥è¯¢æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "# --- ç¤ºä¾‹ï¼šåˆ†æä¸€ä¸ªå¯èƒ½ä½æ•ˆçš„æŸ¥è¯¢ ---\n",
    "# å‡è®¾æˆ‘ä»¬è¦æ ¹æ®è¯¾ç¨‹æ ‡é¢˜çš„å…³é”®è¯å’Œç³»åæ¥æŸ¥æ‰¾è¯¾ç¨‹\n",
    "# è¿™ä¸ªæŸ¥è¯¢åœ¨ `course.title` å’Œ `department.dept_name` ä¸Šæ²¡æœ‰ç´¢å¼•æ—¶å¯èƒ½ä¼šå¾ˆæ…¢\n",
    "slow_query_example = \"\"\"\n",
    "SELECT c.title, c.credits, d.dept_name\n",
    "FROM course AS c\n",
    "JOIN department AS d ON c.dept_name = d.dept_name\n",
    "WHERE c.title LIKE '%Introduction%' AND d.building = 'Watson';\n",
    "\"\"\"\n",
    "\n",
    "analyze_query(slow_query_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759540d0",
   "metadata": {},
   "source": [
    "## 2. MySQL æ€§èƒ½åˆ†æä¸è¯Šæ–­\n",
    "\n",
    "æ€§èƒ½ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥æ˜¯è¯†åˆ«ç“¶é¢ˆã€‚å¯¹äº Text2SQL ç³»ç»Ÿï¼Œæœ€å¸¸è§çš„ç“¶é¢ˆæ˜¯æ•°æ®åº“ç«¯çš„æ…¢æŸ¥è¯¢ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `EXPLAIN` å‘½ä»¤æ¥åˆ†æé‚£äº›ç”± RAG ç³»ç»Ÿç”Ÿæˆçš„ã€æˆ–ä¸ RAG ç›¸å…³çš„ SQL æŸ¥è¯¢ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- è¯†åˆ«ä¸€ä¸ªæˆ–å¤šä¸ªåœ¨ RAG æµç¨‹ä¸­å¸¸ç”¨ä½†æ€§èƒ½å¯èƒ½ä¸ä½³çš„æŸ¥è¯¢ã€‚\n",
    "- ä½¿ç”¨ `EXPLAIN` åˆ†æè¿™äº›æŸ¥è¯¢çš„æ‰§è¡Œè®¡åˆ’ã€‚\n",
    "- é‡ç‚¹å…³æ³¨ `type`ï¼ˆæ˜¯å¦ä¸º `ALL`ï¼Œå³å…¨è¡¨æ‰«æï¼‰ã€`key`ï¼ˆæ˜¯å¦ä½¿ç”¨äº†ç´¢å¼•ï¼‰å’Œ `Extra`ï¼ˆæ˜¯å¦æœ‰ `Using filesort` æˆ– `Using temporary`ï¼‰ç­‰å­—æ®µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ .env æ–‡ä»¶ï¼Œå¦‚æœæ‚¨çš„å‡­æ®å­˜å‚¨åœ¨å…¶ä¸­\n",
    "load_dotenv()\n",
    "\n",
    "# --- ä»ç¯å¢ƒå˜é‡æˆ–ç›´æ¥åœ¨æ­¤å¤„é…ç½®æ•°æ®åº“è¿æ¥ ---\n",
    "# å‚è€ƒæ‚¨çš„ 'æˆ‘çš„æ±‡æ€»å¤‡ä»½.ipynb'ï¼Œæˆ‘ä»¬ä½¿ç”¨ pymysql è¿æ¥\n",
    "# è¯·ç¡®ä¿æ‚¨çš„ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­åŒ…å«ä»¥ä¸‹ä¿¡æ¯\n",
    "DB_USER = os.getenv(\"DB_USER\", \"root\")  # æ‚¨çš„ MySQL ç”¨æˆ·å\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"your_mysql_password\") # æ‚¨çš„ MySQL å¯†ç \n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\") # æ•°æ®åº“ä¸»æœºï¼Œé€šå¸¸æ˜¯ localhost\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"3306\") # æ•°æ®åº“ç«¯å£ï¼Œé»˜è®¤ 3306\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"college_db\") # ç›®æ ‡æ•°æ®åº“åç§°\n",
    "\n",
    "# åˆ›å»º SQLAlchemy è¿æ¥å­—ç¬¦ä¸²\n",
    "# æˆ‘ä»¬ä½¿ç”¨ 'mysql+pymysql' ä½œä¸ºè¿æ¥å™¨\n",
    "DATABASE_URL = f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "try:\n",
    "    # åˆ›å»º SQLAlchemy å¼•æ“\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "\n",
    "    # æµ‹è¯•è¿æ¥\n",
    "    with engine.connect() as connection:\n",
    "        print(\"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼\")\n",
    "        # ç®€å•æŸ¥è¯¢ï¼ŒéªŒè¯è¿æ¥æœ‰æ•ˆ\n",
    "        result = connection.execute(text(\"SELECT 1\"))\n",
    "        print(\" |--- æµ‹è¯•æŸ¥è¯¢ (SELECT 1) è¿”å›:\", result.scalar())\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä½ çš„é…ç½®: {e}\")\n",
    "    print(\"   è¯·ç¡®ä¿ 'pymysql' å’Œ 'SQLAlchemy' å·²å®‰è£…: pip install pymysql sqlalchemy\")\n",
    "    engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06367ed",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®ä¸æ•°æ®åº“è¿æ¥\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `mysql-connector-python` è¿æ¥æ•°æ®åº“ï¼Œ`SQLAlchemy` ä½œä¸º ORMï¼Œ`pandas` è¿›è¡Œæ•°æ®å¤„ç†ï¼Œä»¥åŠ `langchain` æˆ– `llama-index` ä½œä¸º RAG æ¡†æ¶ã€‚\n",
    "\n",
    "**ä»»åŠ¡**:\n",
    "- å¯¼å…¥æ‰€éœ€åº“ã€‚\n",
    "- ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ä¸­å®‰å…¨åœ°åŠ è½½æ•°æ®åº“å‡­æ®ã€‚\n",
    "- åˆ›å»ºä¸€ä¸ª SQLAlchemy å¼•æ“ï¼Œå¹¶æµ‹è¯•ä¸æ•™åŠ¡ç³»ç»Ÿ MySQL æ•°æ®åº“çš„è¿æ¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9635d95",
   "metadata": {},
   "source": [
    "# æ•™åŠ¡ç³»ç»Ÿ RAG + Text2SQL æ€§èƒ½ä¼˜åŒ–æŒ‡å—\n",
    "\n",
    "ä½œä¸ºä¸€åé«˜çº§å…¨æ ˆAIå¼€å‘ä¸“å®¶ï¼Œæœ¬ Notebook å°†æŒ‡å¯¼ä½ å®Œæˆå¯¹ä¸€ä¸ªåŸºäº **MySQL** å’Œ **å¤šæ–‡ä»¶ RAG** çš„æ•™åŠ¡ç³»ç»Ÿçš„æ€§èƒ½åˆ†æä¸ä¼˜åŒ–ã€‚æˆ‘ä»¬å°†ä»æ•°æ®åº“æŸ¥è¯¢ã€ç´¢å¼•ç­–ç•¥ï¼Œåˆ° RAG ç®¡é“ä¸­çš„æ•°æ®åŠ è½½ã€åˆ†å—ã€åµŒå…¥ã€æ£€ç´¢ç­‰ç¯èŠ‚ï¼Œè¿›è¡Œå…¨é¢çš„è¯Šæ–­å’Œæ”¹è¿›ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
